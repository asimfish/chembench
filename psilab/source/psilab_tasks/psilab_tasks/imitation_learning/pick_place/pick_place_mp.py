# Copyright (c) 2022-2024, The PsiRobot Project Developers
# Author: Feng Yunduo
# Date: 2025-04-16
# Vesion: 1.0

""" Python Modules  """ 
from __future__ import annotations
from typing import Any
from collections.abc import Sequence

""" Common Modules  """ 
import os
import torch
from datetime import datetime
from scipy.spatial.transform import Rotation as R

""" Isaac Lab Modules  """ 
from isaaclab.sim import SimulationCfg,PhysxCfg,RenderCfg
from isaaclab.utils import configclass
from isaaclab.envs.common import ViewerCfg


""" Psi Lab Modules  """
from psilab.envs.mp_env import MPEnv 
from psilab.envs.mp_env_cfg import MPEnvCfg
from psilab.utils.timer_utils import Timer
from psilab.eval.grasp_rigid import eval_fail,eval_success
from psilab.utils.data_collect_utils import parse_data,save_data

""" Local Modules """
from ..config_loader import load_pick_place_config

# ========== ä»»åŠ¡é…ç½®ï¼ˆä¿®æ”¹è¿™é‡Œå³å¯åˆ‡æ¢ä¸åŒä»»åŠ¡ï¼‰==========
TARGET_OBJECT_NAME = "erlenmeyer_flask_with_stopper"  # ç›®æ ‡ç‰©ä½“åç§°
TASK_TYPE = "pick_place"       # ä»»åŠ¡ç±»å‹ï¼špick_place

# æ•°æ®æ ¹ç›®å½•ï¼šç»Ÿä¸€å­˜å‚¨åˆ° chembench/data ä¸‹
DATA_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../../../../data"))


@configclass
class PickPlaceEnvCfg(MPEnvCfg):
    """Configuration for Pick and Place environment."""

    # fake params
    action_scale = 0.5
    action_space = 13
    observation_space = 130
    state_space = 130

    # 
    episode_length_s = 3  # å¢åŠ æ—¶é—´ä»¥å®¹çº³æ”¾ç½®é˜¶æ®µ
    decimation = 4
    sample_step = 1

    # viewer config
    viewer = ViewerCfg(
        eye=(0.65,-0.2,1.1),
        lookat=(-15.0,0.1,0.3)
    )

    # simulation  config
    sim: SimulationCfg = SimulationCfg(
        dt = 1 / 120, 
        render_interval=decimation,
        physx = PhysxCfg(
            solver_type = 1,
            max_position_iteration_count = 32,
            max_velocity_iteration_count = 4,
            bounce_threshold_velocity = 0.002,
            enable_ccd=True,
            gpu_found_lost_pairs_capacity = 137401003
        ),
        render=RenderCfg(
            enable_translucency=True,
        ),
    )
    sim.render.rendering_mode = "quality"
    sim.render.antialiasing_mode = "TAA"

    # ========== æŠ“å–é…ç½® ==========
    target_object_name: str = TARGET_OBJECT_NAME
    grasp_offset: list = None  # type: ignore
    grasp_euler_deg: list = None  # type: ignore
    
    # ========== Pick and Place ç‰¹æœ‰é…ç½® ==========
    # æŠ¬èµ·é«˜åº¦ï¼ˆå•ä½ï¼šç±³ï¼Œä¸­é—´ç‚¹çš„é«˜åº¦ï¼‰
    lift_height_desired: float = 0.15
    
    # æ”¾ç½®åç§» [x, y, z]ï¼ˆç›¸å¯¹äºè®¡ç®—å‡ºçš„æ”¾ç½®ä½ç½®çš„åç§»ï¼‰
    place_offset: list = [0, 0, 0.0]  # type: ignore
    
    # æ”¾ç½®è§’åº¦ï¼ˆæ¬§æ‹‰è§’ï¼Œåº¦ï¼‰
    place_euler_deg: list = None  # type: ignore
    
    # è½¨è¿¹æ—¶åºå‚æ•°ï¼ˆ7é˜¶æ®µï¼‰
    phase_ratios: dict = None  # type: ignore
    
    # æ‰‹æŒ‡é—­åˆæ–¹å¼
    smooth_finger_close: bool = True
    # æ‰‹æŒ‡æŠ“å–æ¨¡å¼ï¼š
    # - "all": æ‰€æœ‰æ‰‹æŒ‡éƒ½é—­åˆï¼ˆé»˜è®¤ï¼‰
    # - "pinch": åªæœ‰æ‹‡æŒ‡å’Œé£ŸæŒ‡é—­åˆï¼ˆå¯¹åº”ç´¢å¼• 0,1 å’Œ 5ï¼‰
    # - "no_thumb": å…¶ä»–æ‰‹æŒ‡é—­åˆï¼Œå¤§æ‹‡æŒ‡ä¸é—­åˆ
    finger_grasp_mode: str = "pinch"
    
    # è½¨è¿¹æ¨¡å¼
    trajectory_mode: str = "smooth"
    
    # ========== é¢„æŠ“å–ä½ç½®å‚æ•°ï¼ˆä¾§ä¸Šæ–¹æ¥è¿‘ï¼‰ ==========
    # pre_grasp_height: float = 0.05   # zè½´ä¸Šæ–¹åç§»ï¼ˆç±³ï¼‰
    # pre_grasp_y_offset: float = 0.00  # yè½´åç§»ï¼ˆç±³ï¼‰
    # pre_grasp_x_offset: float = 0.00  # xè½´åç§»ï¼ˆç±³ï¼‰


    pre_grasp_height: float = 0.05
    pre_grasp_y_offset: float = -0.02
    pre_grasp_x_offset: float = -0.02


    # pre_grasp_height: float = 0.05
    # pre_grasp_y_offset: float = -0.02
    # pre_grasp_x_offset: float = -0.02

    # ========== é‡Šæ”¾åä¸­é—´ç‚¹å‚æ•°ï¼ˆé¿å…æ’ç‰©ä½“ï¼‰ ==========
    post_release_height: float = 0.02   # zè½´ä¸Šæ–¹åç§»ï¼ˆç±³ï¼‰
    post_release_y_offset: float = -0.04  # yè½´åç§»ï¼ˆç±³ï¼‰
    post_release_x_offset: float = -0.04  # xè½´åç§»ï¼ˆç±³ï¼‰
    
    # æˆåŠŸåˆ¤æ–­é˜ˆå€¼
    orientation_threshold: float = 0.1
    place_position_threshold: float = 0.025  # æ”¾ç½®ä½ç½®è¯¯å·®é˜ˆå€¼ï¼ˆç±³ï¼‰
    
    # ç‰©ä½“ç›®æ ‡ä½ç½®åç§»ï¼ˆç›¸å¯¹äºåˆå§‹ä½ç½®ï¼‰ï¼š[x_offset, y_offset]ï¼ˆå•ä½ï¼šç±³ï¼‰
    # target_xy_offset: list = [0.10, 0.08]  # type: ignore  # xæ–¹å‘0cmï¼Œyæ–¹å‘5cm
    target_xy_offset: list = [0.08, 0.08]  # type: ignore  # xæ–¹å‘0cmï¼Œyæ–¹å‘5cm
    
    # ç›®æ ‡æˆåŠŸæ¬¡æ•°
    target_success_count: int = 50
    
    # è¾“å‡ºé…ç½®
    output_folder: str = None  # type: ignore
    print_eef_pose: bool = False
    
    def __post_init__(self):
        """
        åˆå§‹åŒ–åä» object_config.json åŠ è½½é»˜è®¤å‚æ•°
        
        è¾“å‡ºè·¯å¾„æ ¼å¼ï¼šchembench/data/motion_plan/pick_place/{ç‰©ä½“åç§°}
        """
        # ä» JSON åŠ è½½ Pick and Place é…ç½®
        pp_config = load_pick_place_config(self.target_object_name)
        
        # è®¾ç½®æŠ“å–åç§»ï¼ˆå¦‚æœæœªæ‰‹åŠ¨æŒ‡å®šï¼‰
        # if self.grasp_offset is None:
        self.grasp_offset = pp_config["grasp_offset"]
        
        # è®¾ç½®æŠ“å–è§’åº¦ï¼ˆå¦‚æœæœªæ‰‹åŠ¨æŒ‡å®šï¼‰
        # if self.grasp_euler_deg is None:
        self.grasp_euler_deg = pp_config["grasp_euler_deg"]
        
        # è®¾ç½®æŠ¬èµ·é«˜åº¦ï¼ˆä» pick_place è¯»å–ï¼‰
        # if self.lift_height_desired == 0.25:
        # self.lift_height_desired = pp_config.get("lift_height", 0.25)
        
        # è®¾ç½®æ”¾ç½®åç§»
        # if self.place_offset == [0, 0, 0.02]:
        self.place_offset = pp_config.get("place_offset", [0, 0, 0.02])
        
        # è®¾ç½®æ”¾ç½®è§’åº¦ï¼ˆå¦‚æœæœªæ‰‹åŠ¨æŒ‡å®šï¼‰
        # if self.place_euler_deg is None:
        self.place_euler_deg = pp_config.get("place_euler_deg", self.grasp_euler_deg)
        
        # è®¾ç½®è½¨è¿¹æ—¶åºå‚æ•°ï¼ˆä» pick_place.timing è¯»å–ï¼‰
        if self.phase_ratios is None:
            timing = pp_config.get("timing", {
                "approach": 0.15,
                "grasp": 0.10,
                "lift": 0.15,
                "transport": 0.15,
                "release": 0.10,
                "post_release": 0.10,  # æ–°å¢ï¼šé‡Šæ”¾åä¸­é—´ç‚¹
                "retreat": 0.25
            })
            # ç¡®ä¿åŒ…å« post_release é”®ï¼ˆå‘åå…¼å®¹æ—§çš„ JSON é…ç½®ï¼‰
            if 'post_release' not in timing:
                old_retreat = timing.get('retreat', 0.35)
                # post_release å  retreat çš„ 40%ï¼Œretreat ä¿ç•™ 60%
                timing['post_release'] = old_retreat * 0.4
                timing['retreat'] = old_retreat * 0.6
            self.phase_ratios = timing
        else:
            # å¦‚æœ phase_ratios å·²ç»è®¾ç½®ï¼Œä¹Ÿç¡®ä¿åŒ…å« post_release é”®
            if 'post_release' not in self.phase_ratios:
                old_retreat = self.phase_ratios.get('retreat', 0.35)
                # post_release å  retreat çš„ 40%ï¼Œretreat ä¿ç•™ 60%
                self.phase_ratios['post_release'] = old_retreat * 0.4
                self.phase_ratios['retreat'] = old_retreat * 0.6
        
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹
        if self.output_folder is None:
            object_name = pp_config.get("name_cn", self.target_object_name)
            self.output_folder = os.path.join(DATA_ROOT, "motion_plan", TASK_TYPE, object_name)

class PickPlaceEnv(MPEnv):

    cfg: PickPlaceEnvCfg

    def __init__(self, cfg: PickPlaceEnvCfg, render_mode: str | None = None, **kwargs):

        super().__init__(cfg, render_mode, **kwargs)

        # instances in scene
        self._robot = self.scene.robots["robot"]
        self._target = self.scene.rigid_objects["bottle"]
        self._visualizer = self.scene.visualizer
        # self._target = self.scene.articulated_objects["bottle"]
        # initialize contact sensor
        self._contact_sensors = {}
        for key in ["hand2_link_base",
                    "hand2_link_1_1",
                    "hand2_link_1_2",
                    "hand2_link_1_3",
                    "hand2_link_2_1",
                    "hand2_link_2_2",
                    "hand2_link_3_1",
                    "hand2_link_3_2",
                    "hand2_link_4_1",
                    "hand2_link_4_2",
                    "hand2_link_5_1",
                    "hand2_link_5_2"]:
            self._contact_sensors[key] = self.scene.sensors[key]

        # joint limit for compute later
        self._joint_limit_lower = self._robot.data.joint_limits[:,:,0].clone()
        self._joint_limit_upper = self._robot.data.joint_limits[:,:,1].clone()

        # joint index: order is arm and hand
        self._arm_joint_index = self._robot.find_joints(self._robot.actuators["arm2"].joint_names,preserve_order=True)[0]
        self._hand_joint_index = self._robot.find_joints(self._robot.actuators["hand2"].joint_names,preserve_order=True)[0][:6]
        self._joint_index = self._arm_joint_index + self._hand_joint_index
        # eef link index
        self._eef_link_index = self._robot.find_bodies("arm2_link7")[0][0]

        # total step number
        self._episode_step = torch.zeros(self.num_envs,device=self.device,dtype=torch.int)
        # 
        self._eef_pose_target = torch.zeros((self.num_envs,self.max_episode_length,7),device=self.device)
        self._hand_pos_target = torch.zeros((self.num_envs,self.max_episode_length,len(self._hand_joint_index)),device=self.device)
        # initialize Timer
        self._timer = Timer()
        # variables
        self._has_contacted = torch.zeros(self.num_envs,device=self.device, dtype=torch.bool) # type: ignore
        self._target_pos_init = torch.zeros((self.num_envs,3),device=self.device)
        self._target_quat_init = torch.zeros((self.num_envs,4),device=self.device)  # åˆå§‹æœå‘ï¼ˆwxyzï¼‰
        
        # ========== Pick and Place å…³é”®å‚æ•° ==========
        # å°†é…ç½®ä¸­çš„ target_xy_offset è½¬æ¢ä¸º tensor
        self._target_xy_offset = torch.tensor(self.cfg.target_xy_offset, dtype=torch.float32, device=self.device)

        self.sim.set_camera_view([-0.7, -5.2, 1.3], [-1.2, -5.2, 1.1])
        # è®¾ç½® RTX æ¸²æŸ“é€‰é¡¹
        import carb
        carb_settings_iface = carb.settings.get_settings()
        carb_settings_iface.set_bool("/rtx/raytracing/fractionalCutoutOpacity", True)
        # 3. å¯é€‰ï¼šç¡®ä¿é€æ˜ç‰©ä½“å‚ä¸ Primary Ray Hit
        carb_settings_iface.set_bool("/rtx/hydra/segmentation/includeTransparent", True)

        # self.sim.render.rendering_mode = "quality"
        # self.sim.render.antialiasing_mode = "TAA"

    def _marker_visualizer(self):
        """
        å¯è§†åŒ–å…³é”®ä½ç½®ï¼ˆPick and Placeï¼‰ï¼š
        1. ç‰©ä½“å½“å‰ä½ç½®å’Œæ—‹è½¬
        2. ä¸­é—´æŠ¬é«˜ç‚¹çš„ä½ç½®å’Œæ—‹è½¬ï¼ˆç‰©ä½“åº”è¯¥è¢«æŠ¬åˆ°çš„ä½ç½®ï¼‰
        3. æœ€ç»ˆç‰©ä½“ç›®æ ‡ä½ç½®å’Œæ—‹è½¬ï¼ˆç‰©ä½“åº”è¯¥è¢«æ”¾ç½®çš„ä½ç½®ï¼‰
        """
        if self.cfg.enable_marker and self._visualizer is not None:
            # 1. ç‰©ä½“å½“å‰ä½ç½®å’Œæ—‹è½¬
            target_current_pos = self._target.data.root_com_state_w[0:1, :3]
            target_current_pos[:,2] = target_current_pos[:, 2]  +  0.05
            target_current_quat = self._target.data.root_com_state_w[0:1, 3:7]
            
            # target_current_pos = self._target.data.root_pos_w[0:1, :] - self._robot.data.root_link_pos_w[0:1, :]
        
            # 2. ä¸­é—´æŠ¬é«˜ç‚¹çš„ä½ç½®å’Œæ—‹è½¬
            # è®¡ç®—ä¸­é—´æŠ¬é«˜ç‚¹ï¼ˆä¸è½¨è¿¹ç”Ÿæˆé€»è¾‘ä¸€è‡´ï¼‰
            target_position_init = self._target_pos_init[0:1, :]  # ç‰©ä½“åˆå§‹ä½ç½® 
            target_xy_offset = self._target_xy_offset.unsqueeze(0)
            
            place_xy = target_position_init[:, :2] + target_xy_offset
            mid_xy = (target_position_init[:, :2] + place_xy) / 2.0
            # mid_xy = place_xy
            mid_z = target_position_init[:, 2] + self.cfg.lift_height_desired
            lift_pos = torch.cat([mid_xy, mid_z.unsqueeze(1)], dim=1)
            # æŠ¬é«˜ç‚¹ä½¿ç”¨ä¸ç‰©ä½“ç›¸åŒçš„æ—‹è½¬
            lift_quat = target_current_quat.clone()
            
            # 3. æœ€ç»ˆç‰©ä½“ç›®æ ‡ä½ç½®å’Œæ—‹è½¬
            # è®¡ç®—ç‰©ä½“æœ€ç»ˆåº”è¯¥åœ¨çš„ä½ç½®ï¼ˆä¸åŒ…å« place_offsetï¼Œé‚£æ˜¯æœ«ç«¯æ‰§è¡Œå™¨çš„åç§»ï¼‰
            object_final_pos = torch.cat([place_xy, target_position_init[:, 2:3]], dim=1)
            object_final_pos[:,2] = 1.02
            # æœ€ç»ˆä½ç½®ä½¿ç”¨ä¸ç‰©ä½“ç›¸åŒçš„æ—‹è½¬
            object_final_quat = target_current_quat.clone()
            
            # æ‹¼æ¥æ‰€æœ‰æ ‡è®°ç‚¹
            marker_pos = torch.cat((
                target_current_pos,   # ç‰©ä½“å½“å‰ä½ç½®
                lift_pos,             # ä¸­é—´æŠ¬é«˜ç‚¹
                object_final_pos,     # ç‰©ä½“æœ€ç»ˆç›®æ ‡ä½ç½®
            ), dim=0)
            
            marker_rot = torch.cat((
                target_current_quat,  # ç‰©ä½“å½“å‰æ—‹è½¬
                lift_quat,            # ä¸­é—´æŠ¬é«˜ç‚¹æ—‹è½¬
                object_final_quat,    # ç‰©ä½“æœ€ç»ˆæ—‹è½¬
            ), dim=0)

            self._visualizer.visualize(marker_pos, marker_rot)

            
    def create_pick_place_trajectory(self, env_ids: torch.Tensor | None):
        """
        åˆ›å»º Pick and Place è½¨è¿¹ï¼ˆ8é˜¶æ®µï¼Œæ–°å¢é‡Šæ”¾åä¸­é—´ç‚¹ï¼‰
        
        æ”¾ç½®ä½ç½®è®¡ç®—é€»è¾‘ï¼š
        - æ”¾ç½®xyä½ç½® = ç‰©ä½“åˆå§‹xy + (0.01, 0.10)  # x+1cm, y+10cm
        - ä¸­é—´æŠ¬é«˜ç‚¹xy = (ç‰©ä½“åˆå§‹xy + æ”¾ç½®xy) / 2  # ä¸­ç‚¹
        - ä¸­é—´æŠ¬é«˜ç‚¹z = cfg.lift_height_desired  # é¢„è®¾é«˜åº¦
        - æœ€ç»ˆæ”¾ç½®ç‚¹ = æ”¾ç½®xyä½ç½® + cfg.place_offset  # åŠ ä¸Šæ”¾ç½®åç§»
        
        è½¨è¿¹é˜¶æ®µï¼ˆæ”¹è¿›æŠ“å–æµç¨‹ï¼Œä¸ grasp_mp ä¸€è‡´ï¼‰ï¼š
        1. approach: ä»å½“å‰ä½ç½®ç§»åŠ¨åˆ°é¢„æŠ“å–ä½ç½®ï¼ˆä¾§ä¸Šæ–¹æ¥è¿‘ï¼‰
        2. descend: ä»é¢„æŠ“å–ä½ç½®ä¸‹é™åˆ°æŠ“å–ä½ç½®
        3. dwell: åœ¨æŠ“å–ä½ç½®ç¨³å®šç­‰å¾…ï¼ˆè®©IKæ”¶æ•›ï¼‰
        4. grasp: æ‰‹æŒ‡é—­åˆæŠ“å–ç‰©ä½“
        5. lift: æŠ¬èµ·åˆ°ä¸­é—´æŠ¬é«˜ç‚¹
        6. transport: ä»ä¸­é—´ç‚¹è¿è¾“åˆ°æœ€ç»ˆæ”¾ç½®ä½ç½®
        7. release: æ¾å¼€æ‰‹æŒ‡
        8. post_release: ç§»åŠ¨åˆ°é‡Šæ”¾åä¸­é—´ç‚¹ï¼ˆé¿å…æ’åˆ°ç‰©ä½“ï¼‰
        9. retreat: æ’¤å›åˆ°æœ€ç»ˆå®‰å…¨ä½ç½®
        """
        env_len = env_ids.shape[0]
        total_steps = self.max_episode_length
        
        # ========== é˜¶æ®µæ—¶é—´åˆ†é… ==========
        # å°† approach æ—¶é—´æ‹†åˆ†ä¸º approach (40%) + descend (50%) + dwell (10%)
        cfg_ratios = self.cfg.phase_ratios
        approach_total = cfg_ratios['approach']
        grasp_total = cfg_ratios['grasp']
        
        approach_end = int(approach_total * 0.4 * total_steps)  # æ¥è¿‘é¢„æŠ“å–ä½ç½®
        descend_end = approach_end + int(approach_total * 0.5 * total_steps)  # ä¸‹é™åˆ°æŠ“å–ä½ç½®
        dwell_end = descend_end + int(approach_total * 0.10 * total_steps)  # ç¨³å®šç­‰å¾…
        grasp_end = dwell_end + int(grasp_total * total_steps)
        lift_end = grasp_end + int(cfg_ratios['lift'] * total_steps)
        transport_end = lift_end + int(cfg_ratios['transport'] * total_steps)
        release_end = transport_end + int(cfg_ratios['release'] * total_steps)
        post_release_end = release_end + int(cfg_ratios['post_release'] * total_steps)  # æ–°å¢
        retreat_end = total_steps
        
        # ========== æŠ“å–å§¿æ€é…ç½® ==========
        grasp_euler_deg = self.cfg.grasp_euler_deg
        grasp_offset = self.cfg.grasp_offset
        
        quat_xyzw = R.from_euler('xyz', grasp_euler_deg, degrees=True).as_quat()
        eff_quat_grasp = torch.tensor([quat_xyzw[3], quat_xyzw[0], quat_xyzw[1], quat_xyzw[2]], 
                                       dtype=torch.float32, device=self.device).unsqueeze(0).repeat(env_len, 1)
        
        # ========== æ”¾ç½®å§¿æ€é…ç½® ==========
        place_euler_deg = self.cfg.place_euler_deg
        place_quat_xyzw = R.from_euler('xyz', place_euler_deg, degrees=True).as_quat()
        eff_quat_place = torch.tensor([place_quat_xyzw[3], place_quat_xyzw[0], place_quat_xyzw[1], place_quat_xyzw[2]], 
                                       dtype=torch.float32, device=self.device).unsqueeze(0).repeat(env_len, 1)
        
        # ========== è®¡ç®—å…³é”®ä½ç½® ==========
        # ç‰©ä½“åˆå§‹ä½ç½®ï¼ˆç›¸å¯¹æœºå™¨äººåŸºåº§ï¼‰
        target_position_init = self._target.data.root_pos_w[env_ids, :] - self._robot.data.root_link_pos_w[env_ids, :]
        
        eff_offset = torch.tensor(grasp_offset, dtype=torch.float32, device=self.device).unsqueeze(0).repeat(env_len, 1)
        
        # å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿
        eef_pos_current = self._robot.data.body_link_pos_w[env_ids, self._eef_link_index, :] - self._robot.data.root_link_pos_w[env_ids, :]
        eef_quat_current = self._robot.data.body_link_quat_w[env_ids, self._eef_link_index, :]
        
        # 0. é¢„æŠ“å–ä½ç½®ï¼ˆæŠ“å–ç‚¹ä¸Šæ–¹ + ä¾§é¢åç§»ï¼Œä»ä¾§ä¸Šæ–¹æ¥è¿‘ï¼‰
        pre_grasp_offset = torch.tensor([self.cfg.pre_grasp_x_offset, self.cfg.pre_grasp_y_offset, self.cfg.pre_grasp_height], 
                                        device=self.device).unsqueeze(0).repeat(env_len, 1)
        pos_pre_grasp = eff_offset + target_position_init + pre_grasp_offset
        
        # 1. æŠ“å–ä½ç½®
        pos_grasp = eff_offset + target_position_init
        
        # 2. æ”¾ç½®xyä½ç½® = ç‰©ä½“åˆå§‹xy + target_xy_offset
        target_xy_offset = self._target_xy_offset.unsqueeze(0).repeat(env_len, 1)
        place_xy = target_position_init[:, :2] + target_xy_offset
        
        # ç‰©ä½“çš„æœ€ç»ˆæ”¾ç½®ä½ç½®ï¼ˆç‰©ä½“ä¸­å¿ƒåº”è¯¥åœ¨çš„ä½ç½®ï¼‰
        object_place_position = torch.cat([place_xy, target_position_init[:, 2:3]], dim=1)
        
        # 3. ä¸­é—´æŠ¬é«˜ç‚¹ = xyä¸­ç‚¹ + (ç‰©ä½“åˆå§‹é«˜åº¦ + æŠ¬é«˜é«˜åº¦)
        mid_xy = (target_position_init[:, :2] + place_xy) / 2.0
        # mid_xy = place_xy
        mid_z = target_position_init[:, 2] + self.cfg.lift_height_desired  # ç›¸å¯¹äºç‰©ä½“åˆå§‹é«˜åº¦
        pos_lift = torch.cat([mid_xy, mid_z.unsqueeze(1)], dim=1)
        pos_lift += eff_offset

        # 4. æœ«ç«¯æ‰§è¡Œå™¨çš„æœ€ç»ˆæ”¾ç½®ä½ç½® = ç‰©ä½“æ”¾ç½®ä½ç½® + place_offsetï¼ˆç±»ä¼¼æŠ“å–æ—¶çš„ grasp_offsetï¼‰
        place_offset_tensor = torch.tensor(self.cfg.place_offset, dtype=torch.float32, device=self.device).unsqueeze(0).repeat(env_len, 1)
        pos_place = object_place_position + place_offset_tensor  # æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
        
        # 5. é‡Šæ”¾åä¸­é—´ç‚¹ï¼ˆé¿å…ç›´æ¥ä¸Šç§»æ’åˆ°ç‰©ä½“ï¼‰
        post_release_offset = torch.tensor([self.cfg.post_release_x_offset, self.cfg.post_release_y_offset, self.cfg.post_release_height], 
                                           device=self.device).unsqueeze(0).repeat(env_len, 1)
        pos_post_release = pos_place + post_release_offset
        
        # 6. æœ€ç»ˆæ’¤å›ä½ç½®ï¼ˆé‡Šæ”¾åä¸­é—´ç‚¹ä¸Šæ–¹å†æŠ¬é«˜5cmï¼‰
        retreat_offset = torch.tensor([0, 0, 0.12], device=self.device).unsqueeze(0).repeat(env_len, 1)
        pos_retreat = pos_post_release + retreat_offset
        
        # ========== æ‰‹æŒ‡ä½ç½® ==========
        hand_pos_open = self._joint_limit_upper[env_ids, :][:, self._hand_joint_index]
        hand_pos_closed = self._joint_limit_lower[env_ids, :][:, self._hand_joint_index]
        hand_pos_closed[:, 0] = self._joint_limit_upper[env_ids, :][:, self._hand_joint_index[0]]
        
        if self.cfg.finger_grasp_mode == "pinch":
            hand_pos_closed[:, 2] = hand_pos_open[:, 2]
            hand_pos_closed[:, 3] = hand_pos_open[:, 3]
            hand_pos_closed[:, 4] = hand_pos_open[:, 4]
        
        if self.cfg.finger_grasp_mode == "no_thumb":
            hand_pos_closed[:, 5] = self._joint_limit_upper[env_ids, :][:, self._hand_joint_index[1]]
        
        
        # ========== ç”Ÿæˆè½¨è¿¹ ==========
        for step in range(total_steps):
            if step < approach_end:
                # é˜¶æ®µ1: æ¥è¿‘ - ä»å½“å‰ä½ç½®ç§»åŠ¨åˆ°é¢„æŠ“å–ä½ç½®ï¼ˆä¾§ä¸Šæ–¹ï¼‰
                t_normalized = step / max(approach_end, 1)
                t_smooth = self._smooth_approach_interpolation(torch.tensor(t_normalized, device=self.device))
                pos_interp = eef_pos_current + t_smooth * (pos_pre_grasp - eef_pos_current)
                t_batch = torch.full((env_len,), t_smooth.item(), device=self.device)
                quat_interp = self._slerp_batch(eef_quat_current, eff_quat_grasp, t_batch)
                hand_interp = hand_pos_open
                
            elif step < descend_end:
                # é˜¶æ®µ2: ä¸‹é™ - ä»é¢„æŠ“å–ä½ç½®ä¸‹é™åˆ°æŠ“å–ä½ç½®
                t_normalized = (step - approach_end) / max(descend_end - approach_end, 1)
                t_smooth = self._smooth_approach_interpolation(torch.tensor(t_normalized, device=self.device))
                pos_interp = pos_pre_grasp + t_smooth * (pos_grasp - pos_pre_grasp)
                quat_interp = eff_quat_grasp
                hand_interp = hand_pos_open
                
            elif step < dwell_end:
                # é˜¶æ®µ3: ç¨³å®š - åœ¨æŠ“å–ä½ç½®ä¿æŒä¸åŠ¨ï¼Œç­‰å¾…IKæ”¶æ•›
                # ä½ç½®ç²¾ç¡®ä¿æŒåœ¨æŠ“å–ä½ç½®ï¼ˆå…³é”®ï¼šæé«˜æŠ“å–ç²¾åº¦ï¼‰
                pos_interp = pos_grasp
                quat_interp = eff_quat_grasp
                hand_interp = hand_pos_open
                
            elif step < grasp_end:
                # é˜¶æ®µ4: æŠ“å–ï¼ˆæ‰‹æŒ‡é—­åˆï¼‰
                pos_interp = pos_grasp
                quat_interp = eff_quat_grasp
                
                # æ‰‹æŒ‡é—­åˆæ–¹å¼
                if self.cfg.smooth_finger_close:
                    # å¹³æ»‘é—­åˆï¼šä½¿ç”¨æœ€å°åŠ åŠ é€Ÿåº¦æ’å€¼
                    t_normalized = (step - dwell_end) / max(grasp_end - dwell_end, 1)
                    t_smooth = self._minimum_jerk_interpolation(torch.tensor(t_normalized, device=self.device))
                    hand_interp = hand_pos_open + t_smooth * (hand_pos_closed - hand_pos_open)
                else:
                    # ç›´æ¥é—­åˆï¼šæ•´ä¸ª grasp é˜¶æ®µéƒ½ä¿æŒé—­åˆçŠ¶æ€
                    hand_interp = hand_pos_closed
                
            elif step < lift_end:
                # é˜¶æ®µ5: æŠ¬èµ·åˆ°ä¸­é—´æŠ¬é«˜ç‚¹
                t_normalized = (step - grasp_end) / max(lift_end - grasp_end, 1)
                t_smooth = self._minimum_jerk_interpolation(torch.tensor(t_normalized, device=self.device))
                pos_interp = pos_grasp + t_smooth * (pos_lift - pos_grasp)
                # å§¿æ€ä»æŠ“å–å§¿æ€æ¸å˜åˆ°æ”¾ç½®å§¿æ€
                t_batch = torch.full((env_len,), t_smooth.item(), device=self.device)
                quat_interp = self._slerp_batch(eff_quat_grasp, eff_quat_place, t_batch)
                hand_interp = hand_pos_closed
                
            elif step < transport_end:
                # é˜¶æ®µ6: ä»ä¸­é—´ç‚¹è¿è¾“åˆ°æœ€ç»ˆæ”¾ç½®ä½ç½®
                t_normalized = (step - lift_end) / max(transport_end - lift_end, 1)
                t_smooth = self._minimum_jerk_interpolation(torch.tensor(t_normalized, device=self.device))
                pos_interp = pos_lift + t_smooth * (pos_place - pos_lift)
                quat_interp = eff_quat_place
                hand_interp = hand_pos_closed
                
            elif step < release_end:
                # é˜¶æ®µ7: é‡Šæ”¾ï¼ˆæ‰‹æŒ‡æ‰“å¼€ï¼‰
                pos_interp = pos_place
                quat_interp = eff_quat_place
                t_normalized = (step - transport_end) / max(release_end - transport_end, 1)
                t_smooth = self._minimum_jerk_interpolation(torch.tensor(t_normalized, device=self.device))
                hand_interp = hand_pos_closed + t_smooth * (hand_pos_open - hand_pos_closed)
                
            elif step < post_release_end:
                # é˜¶æ®µ8: ç§»åŠ¨åˆ°é‡Šæ”¾åä¸­é—´ç‚¹ï¼ˆé¿å…æ’åˆ°ç‰©ä½“ï¼‰
                t_normalized = (step - release_end) / max(post_release_end - release_end, 1)
                t_smooth = self._minimum_jerk_interpolation(torch.tensor(t_normalized, device=self.device))
                pos_interp = pos_place + t_smooth * (pos_post_release - pos_place)
                quat_interp = eff_quat_place
                hand_interp = hand_pos_open
                
            else:
                # é˜¶æ®µ9: æ’¤å›åˆ°æœ€ç»ˆå®‰å…¨ä½ç½®
                t_normalized = (step - post_release_end) / max(retreat_end - post_release_end, 1)
                t_smooth = self._minimum_jerk_interpolation(torch.tensor(t_normalized, device=self.device))
                pos_interp = pos_post_release + t_smooth * (pos_retreat - pos_post_release)
                quat_interp = eff_quat_place
                hand_interp = hand_pos_open
            
            # å­˜å‚¨è½¨è¿¹ç‚¹
            self._eef_pose_target[env_ids, step, :3] = pos_interp
            self._eef_pose_target[env_ids, step, 3:7] = quat_interp
            self._hand_pos_target[env_ids, step, :] = hand_interp

    def _minimum_jerk_interpolation(self, t: torch.Tensor) -> torch.Tensor:
        """
        æœ€å°åŠ åŠ é€Ÿåº¦è½¨è¿¹æ’å€¼å‡½æ•° (Minimum Jerk Trajectory)
        s(t) = 10*t^3 - 15*t^4 + 6*t^5
        
        ç‰¹æ€§ï¼š
        - s(0) = 0, s(1) = 1
        - s'(0) = s'(1) = 0 (èµ·ç‚¹å’Œç»ˆç‚¹é€Ÿåº¦ä¸º0)
        - s''(0) = s''(1) = 0 (èµ·ç‚¹å’Œç»ˆç‚¹åŠ é€Ÿåº¦ä¸º0)
        
        Args:
            t: å½’ä¸€åŒ–æ—¶é—´ [0, 1]ï¼Œshape: (N,) æˆ–æ ‡é‡
        Returns:
            æ’å€¼ç³»æ•°ï¼Œshape: åŒè¾“å…¥
        """
        t = torch.clamp(t, 0.0, 1.0)
        return 10 * t**3 - 15 * t**4 + 6 * t**5
    
    def _smooth_approach_interpolation(self, t: torch.Tensor) -> torch.Tensor:
        """
        æ›´å¹³æ»‘çš„æ¥è¿‘æ’å€¼å‡½æ•°ï¼ˆæœ«ç«¯å‡é€Ÿæ›´å¹³ç¼“ï¼‰
        
        ä½¿ç”¨ 7 é˜¶å¤šé¡¹å¼ï¼Œåœ¨æœ«ç«¯æœ‰æ›´é•¿çš„å‡é€ŸåŒºé—´
        s(t) = 35*t^4 - 84*t^5 + 70*t^6 - 20*t^7
        
        ç‰¹æ€§ï¼š
        - s(0) = 0, s(1) = 1
        - s'(0) = s'(1) = 0 (èµ·ç‚¹å’Œç»ˆç‚¹é€Ÿåº¦ä¸º0)
        - s''(0) = s''(1) = 0 (èµ·ç‚¹å’Œç»ˆç‚¹åŠ é€Ÿåº¦ä¸º0)
        - s'''(0) = s'''(1) = 0 (èµ·ç‚¹å’Œç»ˆç‚¹åŠ åŠ é€Ÿåº¦ä¸º0)
        - ç›¸æ¯” minimum jerkï¼Œæœ«ç«¯å‡é€Ÿæ›´åŠ å¹³ç¼“
        
        Args:
            t: å½’ä¸€åŒ–æ—¶é—´ [0, 1]ï¼Œshape: (N,) æˆ–æ ‡é‡
        Returns:
            æ’å€¼ç³»æ•°ï¼Œshape: åŒè¾“å…¥
        """
        t = torch.clamp(t, 0.0, 1.0)
        return 35 * t**4 - 84 * t**5 + 70 * t**6 - 20 * t**7
    
    def _quasi_linear_interpolation(self, t: torch.Tensor, smooth_ratio: float = 0.05) -> torch.Tensor:
        """
        å‡†çº¿æ€§æ’å€¼å‡½æ•° - é€‚åˆ Diffusion Policy è®­ç»ƒ
        
        é€Ÿåº¦æ›²çº¿è¿‘ä¼¼æ¢¯å½¢ï¼š
        - å¼€å¤´ smooth_ratio æ—¶é—´ï¼šå¹³æ»‘åŠ é€Ÿï¼ˆä½¿ç”¨åŠä¸ªä½™å¼¦ï¼‰
        - ä¸­é—´ 1-2*smooth_ratio æ—¶é—´ï¼šæ’å®šé€Ÿåº¦ï¼ˆçº¿æ€§ï¼‰
        - ç»“å°¾ smooth_ratio æ—¶é—´ï¼šå¹³æ»‘å‡é€Ÿï¼ˆä½¿ç”¨åŠä¸ªä½™å¼¦ï¼‰
        
        å…³é”®ç‰¹æ€§ï¼š
        - 95% æ—¶é—´ä¿æŒæ’å®šé€Ÿåº¦ï¼Œæ•°æ®åˆ†å¸ƒå‡åŒ€
        - é¦–å°¾æœ‰å¾®å°å¹³æ»‘ï¼Œé¿å…é€Ÿåº¦çªå˜ï¼ˆå¯¹ IK æ±‚è§£å‹å¥½ï¼‰
        - é€Ÿåº¦å˜åŒ–å¾ˆå°ï¼Œdiffusion æ¨¡å‹å®¹æ˜“æ‹Ÿåˆ
        
        Args:
            t: å½’ä¸€åŒ–æ—¶é—´ [0, 1]ï¼Œshape: (N,) æˆ–æ ‡é‡
            smooth_ratio: é¦–å°¾å¹³æ»‘åŒºé—´å æ¯”ï¼Œé»˜è®¤ 0.05 (5%)
        Returns:
            æ’å€¼ç³»æ•°ï¼Œshape: åŒè¾“å…¥
        """
        t = torch.clamp(t, 0.0, 1.0)
        sr = smooth_ratio
        
        # æ¢¯å½¢é€Ÿåº¦æ›²çº¿çš„ä½ç§»è®¡ç®—
        # æ’é€Ÿæ®µé€Ÿåº¦ v = 1 / (1 - sr)ï¼Œè¿™æ ·æ€»ä½ç§»ä¸º 1
        # åŠ é€Ÿæ®µä½ç§» = sr * v / 2 = sr / (2 * (1 - sr))
        # åŒ€é€Ÿæ®µä½ç§» = (1 - 2*sr) * v = (1 - 2*sr) / (1 - sr)
        # å‡é€Ÿæ®µä½ç§» = sr * v / 2 = sr / (2 * (1 - sr))
        
        v_const = 1.0 / (1.0 - sr)  # æ’é€Ÿæ®µé€Ÿåº¦
        
        # åˆ†æ®µè®¡ç®—
        result = torch.zeros_like(t)
        
        # åŠ é€Ÿæ®µ [0, sr]ï¼šä½¿ç”¨åŠä¸ªæ­£å¼¦å®ç°å¹³æ»‘åŠ é€Ÿ
        mask_accel = t < sr
        if mask_accel.any():
            t_accel = t[mask_accel] / sr  # å½’ä¸€åŒ–åˆ° [0, 1]
            # ä½ç§» = ç§¯åˆ† v_const * sin(Ï€*Ï„/2) dÏ„ from 0 to t_accel
            # = sr * v_const * (1 - cos(Ï€*t_accel/2)) * 2/Ï€
            # ç®€åŒ–ï¼šä½¿ç”¨ (1 - cos(Ï€*t/2)) å½¢å¼ï¼Œæœ«ç«¯é€Ÿåº¦ä¸º v_const
            s_accel = sr * v_const * (1.0 - torch.cos(t_accel * torch.pi / 2)) * 2.0 / torch.pi
            result[mask_accel] = s_accel
        
        # åŒ€é€Ÿæ®µ [sr, 1-sr]ï¼šçº¿æ€§æ’å€¼
        mask_const = (t >= sr) & (t < 1 - sr)
        if mask_const.any():
            t_const = t[mask_const]
            # åŠ é€Ÿæ®µç»“æŸä½ç½®
            s_accel_end = sr * v_const * 2.0 / torch.pi
            # åŒ€é€Ÿæ®µä½ç§»
            s_const = s_accel_end + v_const * (t_const - sr)
            result[mask_const] = s_const
        
        # å‡é€Ÿæ®µ [1-sr, 1]ï¼šä½¿ç”¨åŠä¸ªä½™å¼¦å®ç°å¹³æ»‘å‡é€Ÿ
        mask_decel = t >= 1 - sr
        if mask_decel.any():
            t_decel = (t[mask_decel] - (1 - sr)) / sr  # å½’ä¸€åŒ–åˆ° [0, 1]
            # å‡é€Ÿæ®µèµ·å§‹ä½ç½®
            s_accel_end = sr * v_const * 2.0 / torch.pi
            s_const_end = s_accel_end + v_const * (1 - 2 * sr)
            # å‡é€Ÿæ®µä½ç§»ï¼ˆä½¿ç”¨ sin å®ç°å‡é€Ÿï¼‰
            s_decel = s_const_end + sr * v_const * (torch.sin(t_decel * torch.pi / 2)) * 2.0 / torch.pi
            result[mask_decel] = s_decel
        
        # å½’ä¸€åŒ–åˆ° [0, 1]ï¼ˆç”±äºæ•°å€¼è®¡ç®—ï¼Œæœ«ç«¯å¯èƒ½ä¸ç²¾ç¡®ä¸º 1ï¼‰
        result = result / (sr * v_const * 4.0 / torch.pi + v_const * (1 - 2 * sr))
        
        return torch.clamp(result, 0.0, 1.0)
    
    def _slerp_batch(self, q0: torch.Tensor, q1: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        """
        æ‰¹é‡çƒé¢çº¿æ€§æ’å€¼ (SLERP) for quaternions (wxyz format)
        
        Args:
            q0: èµ·å§‹å››å…ƒæ•° [env_len, 4] (wxyz)
            q1: ç›®æ ‡å››å…ƒæ•° [env_len, 4] (wxyz)
            t: æ’å€¼ç³»æ•° [env_len] æˆ– [env_len, 1]ï¼ŒèŒƒå›´ [0, 1]
        Returns:
            æ’å€¼åçš„å››å…ƒæ•° [env_len, 4] (wxyz)
        """
        if t.dim() == 1:
            t = t.unsqueeze(1)  # [env_len, 1]
        
        # å½’ä¸€åŒ–å››å…ƒæ•°
        q0 = q0 / (torch.norm(q0, dim=1, keepdim=True) + 1e-8)
        q1 = q1 / (torch.norm(q1, dim=1, keepdim=True) + 1e-8)
        
        # è®¡ç®—ç‚¹ç§¯
        dot = torch.sum(q0 * q1, dim=1, keepdim=True)
        
        # å¦‚æœç‚¹ç§¯ä¸ºè´Ÿï¼Œåè½¬ä¸€ä¸ªå››å…ƒæ•°ä»¥å–æœ€çŸ­è·¯å¾„
        q1 = torch.where(dot < 0, -q1, q1)
        dot = torch.abs(dot)
        
        # å½“å››å…ƒæ•°éå¸¸æ¥è¿‘æ—¶ï¼Œä½¿ç”¨çº¿æ€§æ’å€¼é¿å…æ•°å€¼é—®é¢˜
        linear_threshold = 0.9995
        
        # SLERP æ’å€¼
        theta = torch.acos(torch.clamp(dot, -1.0, 1.0))
        sin_theta = torch.sin(theta)
        
        # é¿å…é™¤é›¶
        safe_sin_theta = torch.where(sin_theta.abs() < 1e-6, torch.ones_like(sin_theta), sin_theta)
        
        s0 = torch.sin((1.0 - t) * theta) / safe_sin_theta
        s1 = torch.sin(t * theta) / safe_sin_theta
        
        # å½“æ¥è¿‘æ—¶ä½¿ç”¨çº¿æ€§æ’å€¼
        s0 = torch.where(dot > linear_threshold, 1.0 - t, s0)
        s1 = torch.where(dot > linear_threshold, t, s1)
        
        result = s0 * q0 + s1 * q1
        
        # å½’ä¸€åŒ–ç»“æœ
        return result / (torch.norm(result, dim=1, keepdim=True) + 1e-8)

    def step(self,actions):
        
        # set target
        eef_pose_target = torch.tensor([],device=self.device)
        hand_pos_target = torch.tensor([],device=self.device)
        # 
        for i in range(self.num_envs):
            eef_pose_target = torch.cat((eef_pose_target,self._eef_pose_target[i,self._episode_step[i],:].unsqueeze(0)), dim=0)
            hand_pos_target= torch.cat((hand_pos_target,self._hand_pos_target[i,self._episode_step[i],:].unsqueeze(0)), dim=0)

        self._robot.set_ik_command({"arm2":eef_pose_target})
        self._robot.set_joint_position_target(hand_pos_target,self._robot.actuators["hand2"].joint_indices[:6]) # type: ignore

        if self.cfg.print_eef_pose:
            # ========== è¾“å‡ºæœ«ç«¯æ‰§è¡Œå™¨ä½ç½®å’Œæ—‹è½¬ ==========
            # è·å–å½“å‰æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
            eef_pos_w = self._robot.data.body_link_pos_w[:, self._eef_link_index, :]
            eef_quat_w = self._robot.data.body_link_quat_w[:, self._eef_link_index, :]
            # è·å–ç‰©ä½“ä½ç½®
            object_pos_w = self._target.data.root_pos_w
            # è®¡ç®—ç›¸å¯¹ä½ç½®ï¼ˆEEFç›¸å¯¹äºç‰©ä½“ï¼‰
            eef_pos_rel = eef_pos_w - object_pos_w
            # æ‰“å°ç¬¬ä¸€ä¸ªç¯å¢ƒçš„ä¿¡æ¯ï¼ˆé¿å…è¾“å‡ºè¿‡å¤šï¼‰
            pos_rel = eef_pos_rel[0].cpu().numpy()
            quat = eef_quat_w[0].cpu().numpy()  # wxyz æ ¼å¼
            target_pos = eef_pose_target[0, :3].cpu().numpy()
            target_quat = eef_pose_target[0, 3:7].cpu().numpy()
            step = self._episode_step[0].item()
            # å››å…ƒæ•°è½¬æ¬§æ‹‰è§’ (wxyz -> xyzw for scipy, then to degrees)
            quat_xyzw = [quat[1], quat[2], quat[3], quat[0]]  # wxyz -> xyzw
            euler_deg = R.from_quat(quat_xyzw).as_euler('xyz', degrees=True)
            target_quat_xyzw = [target_quat[1], target_quat[2], target_quat[3], target_quat[0]]
            target_euler_deg = R.from_quat(target_quat_xyzw).as_euler('xyz', degrees=True)
            # print(f"[Step {step:3d}] EEFç›¸å¯¹ç‰©ä½“: [{pos_rel[0]:7.4f}, {pos_rel[1]:7.4f}, {pos_rel[2]:7.4f}] | "
            #     f"ç›®æ ‡: [{target_pos[0]:7.4f}, {target_pos[1]:7.4f}, {target_pos[2]:7.4f}] | "
            #     f"è§’åº¦(xyz): [{euler_deg[0]:7.2f}Â°, {euler_deg[1]:7.2f}Â°, {euler_deg[2]:7.2f}Â°]")

        # self._target_dof_vel = (self._curr_targets[:, self._robot_index]- self._robot.data.joint_pos[:, self._robot_index]) / self.cfg.sim.dt
        # self._robot.set_joint_position_target(self._curr_targets[:, self._arm_joint_index], joint_ids=self._arm_joint_index)
        # self._robot.set_joint_velocity_target(self._target_dof_vel, joint_ids=self._arm_joint_index)

        # sim step according to decimation
        for i in range(self.cfg.decimation):
            # sim step
            self.sim_step()
        
        # update episode step
        self._episode_step+=1
        
        self._episode_step = torch.clamp(
            self._episode_step,
            None,
            (self.max_episode_length-1)*  torch.ones_like(self._episode_step)
        )
        
        self._marker_visualizer()
        return super().step(actions)
        
    def sim_step(self):

        # 
        self._robot.ik_step()
        #
        super().sim_step()
        
        # parse sim data
        if self.cfg.enable_output and self._sim_step_counter % self.cfg.sample_step == 0:
            parse_data(
                sim_time=self._sim_step_counter * self.cfg.sim.dt,
                data = self._data,
                scene = self.scene
            )


        ##æ˜¯å¦å®æ—¶æŸ¥çœ‹maskå›¾ç‰‡
        # import matplotlib.pyplot as plt
        # head_camera_mask = self._robot.tiled_cameras["chest_camera"].data.output["instance_segmentation_fast"][0,:,:,:].cpu().numpy()
        # # head_camera_mask = self._robot.tiled_cameras["chest_camera"].data.output["instance_segmentation_fast"][0,:,:,:].cpu().numpy()
        # # head_camera_depth = self._robot.tiled_cameras["chest_camera"].data.output["depth"][0,:,:,:].cpu().numpy()
        # # head_camera_normal = self._robot.tiled_cameras["chest_camera"].data.output["normals"][0,:,:,:].cpu().numpy()
       
        # # plt.figure(figsize=(10, 10))
        # plt.imshow(head_camera_mask)
        # # plt.subplot(1, 3, 2)
        # # plt.imshow(head_camera_depth)
        # # plt.subplot(1, 3, 3)
        # # plt.imshow(head_camera_normal)
        # plt.show()
        # import time
        # time.sleep(0.1)


        # chest_camera_mask = self._robot.tiled_cameras["chest_camera"].data.output["instance_segmentation_fast"]
        
        # ========== å®æ—¶æ‰“å°æœ«ç«¯æ‰§è¡Œå™¨ä¿¡æ¯ ==========
        if self._sim_step_counter % 10 == 0:  # æ¯10æ­¥æ‰“å°ä¸€æ¬¡ï¼Œé¿å…è¾“å‡ºè¿‡å¤š
            # è·å–æœ«ç«¯æ‰§è¡Œå™¨ä½å§¿ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
            eef_pos_w = self._robot.data.body_link_pos_w[0, self._eef_link_index, :]
            eef_quat_w = self._robot.data.body_link_quat_w[0, self._eef_link_index, :]
            
            # è·å–ç‰©ä½“å½“å‰ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
            object_pos_w = self._target.data.root_pos_w[0, :]
            
            # è®¡ç®—æœ«ç«¯æ‰§è¡Œå™¨ç›¸å¯¹ç‰©ä½“å½“å‰ä½ç½®çš„åç§»
            eef_offset_current = eef_pos_w - object_pos_w
            
            # è®¡ç®—ç‰©ä½“çš„æœ€ç»ˆç›®æ ‡ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
            # ç‰©ä½“åˆå§‹ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ï¼‰
            target_pos_init_w = self._target_pos_init[0, :]
            # ç›®æ ‡xyåç§»
            target_xy_offset = self._target_xy_offset
            # æœ€ç»ˆç›®æ ‡xyä½ç½®
            place_xy = target_pos_init_w[:2] + target_xy_offset
            # ç‰©ä½“çš„æœ€ç»ˆç›®æ ‡ä½ç½®ï¼ˆç‰©ä½“ä¸­å¿ƒåº”è¯¥åœ¨çš„ä½ç½®ï¼‰
            object_place_position_w = torch.cat([place_xy, target_pos_init_w[2:3]], dim=0)
            
            # è®¡ç®—æœ«ç«¯æ‰§è¡Œå™¨ç›¸å¯¹ç‰©ä½“æœ€ç»ˆç›®æ ‡ä½ç½®çš„åç§»
            eef_offset_target = eef_pos_w - object_place_position_w
            
            # è®¡ç®—ç‰©ä½“å½“å‰ä½ç½®åˆ°æœ€ç»ˆç›®æ ‡ä½ç½®çš„è·ç¦»
            object_to_target_distance = torch.norm(object_pos_w - object_place_position_w).item()
            
            # å››å…ƒæ•°è½¬æ¬§æ‹‰è§’ (wxyz -> xyzw for scipy, then to degrees)
            quat_wxyz = eef_quat_w.cpu().numpy()
            quat_xyzw = [quat_wxyz[1], quat_wxyz[2], quat_wxyz[3], quat_wxyz[0]]  # wxyz -> xyzw
            euler_deg = R.from_quat(quat_xyzw).as_euler('xyz', degrees=True)
            
            # è·å–å½“å‰episodeæ­¥æ•°
            current_step = self._episode_step[0].item()
            
            # print(f"\n[Step {current_step:3d} | Sim {self._sim_step_counter:5d}]")
            # print(f"  EEFâ†’ç‰©ä½“å½“å‰: [{eef_offset_current[0]:7.4f}, {eef_offset_current[1]:7.4f}, {eef_offset_current[2]:7.4f}]")
            # print(f"  EEFâ†’æ”¾ç½®ç›®æ ‡: [{eef_offset_target[0]:7.4f}, {eef_offset_target[1]:7.4f}, {eef_offset_target[2]:7.4f}]")
            # print(f"  ç‰©ä½“â†’ç›®æ ‡è·ç¦»: {object_to_target_distance:7.4f}m")
            # print(f"  EEFè§’åº¦(xyz): [{euler_deg[0]:7.2f}Â°, {euler_deg[1]:7.2f}Â°, {euler_deg[2]:7.2f}Â°]")
        
        # get dones
        success, fail, time_out = self._get_dones()
        reset = (success | fail | time_out)
        # get ids of envs to reset
        reset_ids = torch.nonzero(reset==True).squeeze()
        # bug: if single index, squeeze will change tensor to torch.Size([])
        reset_ids = reset_ids.unsqueeze(0) if reset_ids.size()==torch.Size([]) else reset_ids
        # get ids of envs completed successfully
        success_ids = torch.nonzero(success==True).squeeze().tolist()
        # bug: if single index, squeeze will change tensor to torch.Size([])
        success_ids = [success_ids] if type(success_ids)==int else success_ids
        
        # reset envs
        if len(reset_ids) > 0:
            # 
            self._reset_idx(reset_ids,success_ids)  # type: ignore

            # update articulation kinematics
            self.scene.write_data_to_sim()
            self.sim.forward()

            # if sensors are added to the scene, make sure we render to reflect changes in reset
            if self.sim.has_rtx_sensors() and self.cfg.rerender_on_reset:
                self.sim.render()
        
    def reset(self, seed: int | None = None, options: dict[str, Any] | None = None):

        #
        super().reset()

    def _eval_fail_moved_without_contact(self) -> torch.Tensor:
        """
        è¯„ä¼°ç‰©ä½“åœ¨æœªæ¥è§¦æ—¶æ˜¯å¦è¢«ç§»åŠ¨ï¼ˆè¢«æ¨åŠ¨/ç¢°æ’ï¼‰
        
        å¤±è´¥æ¡ä»¶ï¼šç‰©ä½“æœªè¢«æ¥è§¦ï¼Œä½† z æ–¹å‘ä½ç§»è¶…è¿‡ 2cm
        
        Returns:
            bfailed: å¤±è´¥æ ‡å¿— [N]
        """
        # æ£€æŸ¥ç‰©ä½“æ˜¯å¦æœªè¢«æ¥è§¦
        not_contacted = ~self._has_contacted
        
        # è®¡ç®— z æ–¹å‘ä½ç§»
        current_z = self._target.data.root_pos_w[:, 2]
        height_diff = current_z - self._target_pos_init[:, 2]
        
        # ç‰©ä½“æœªè¢«æ¥è§¦ä½† z æ–¹å‘ç§»åŠ¨è¶…è¿‡ 2cmï¼Œåˆ¤å®šä¸ºå¤±è´¥
        moved_too_much = height_diff > 0.02
        
        bfailed = not_contacted & moved_too_much
        
        return bfailed

    def _quat_orientation_loss(self, quat_init: torch.Tensor, quat_current: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ä¸¤ä¸ªå››å…ƒæ•°ä¹‹é—´çš„ pitch+roll æœå‘åå·®
        
        è¿”å›å€¼ âˆˆ [0, 1]ï¼š
        - 0: æœå‘å®Œå…¨ä¸€è‡´
        - 1: ä¸Šä¸‹é¢ å€’ï¼ˆ180Â°åå·®ï¼‰
        
        Args:
            quat_init: åˆå§‹å››å…ƒæ•° [N, 4] (wxyz)
            quat_current: å½“å‰å››å…ƒæ•° [N, 4] (wxyz)
        Returns:
            loss: æœå‘åå·® [N]
        """
        # å››å…ƒæ•°åˆ†é‡ (wxyz format)
        aw, ax, ay, az = quat_init.unbind(-1)
        bw, bx, by, bz = quat_current.unbind(-1)
        
        # è®¡ç®— conj(a)
        cw, cx, cy, cz = aw, -ax, -ay, -az
        
        # è®¡ç®—ç›¸å¯¹å››å…ƒæ•° Î”q = conj(a) âŠ— b
        rw = cw * bw - cx * bx - cy * by - cz * bz
        rx = cw * bx + cx * bw + cy * bz - cz * by
        ry = cw * by - cx * bz + cy * bw + cz * bx
        rz = cw * bz + cx * by - cy * bx + cz * bw
        
        # å½’ä¸€åŒ–ï¼ˆæ•°å€¼å®‰å…¨ï¼‰
        norm = torch.sqrt(rw * rw + rx * rx + ry * ry + rz * rz) + 1e-8
        rx, ry = rx / norm, ry / norm
        
        # pitch+roll è¯¯å·®ï¼šsinÂ²(Î¸_pr/2) âˆˆ [0,1]
        loss = rx * rx + ry * ry
        return loss

    def _eval_success_pick_place(self) -> torch.Tensor:
        """
        è¯„ä¼° Pick and Place æ˜¯å¦æˆåŠŸ
        
        æˆåŠŸæ¡ä»¶ï¼š
        1. ç‰©ä½“è¢«æ”¾ç½®åœ¨ç›®æ ‡ä½ç½®é™„è¿‘ï¼ˆxyå¹³é¢è¯¯å·®å°äºé˜ˆå€¼ï¼‰
        2. ç‰©ä½“é«˜åº¦ä¸åˆå§‹é«˜åº¦å·®è·ä¸å¤§äº1cmï¼ˆç¡®ä¿åœ¨æ¡Œé¢ä¸Šï¼‰
        3. ç‰©ä½“æœå‘åç¦»ä¸è¶…è¿‡é˜ˆå€¼
        4. æ‰‹æŒ‡å·²æ¾å¼€ï¼ˆæ‰€æœ‰æ‰‹æŒ‡æ¥è§¦åŠ›ä¸º0ï¼‰
        5. æœ«ç«¯æ‰§è¡Œå™¨å·²æŠ¬é«˜åˆ°ç‰©ä½“åˆå§‹é«˜åº¦ + 0.15ç±³
        
        ç›®æ ‡ä½ç½®ï¼ˆç‰©ä½“ä¸­å¿ƒï¼‰= åˆå§‹ä½ç½® + target_xy_offset
        """
        # 1. è®¡ç®—ç›®æ ‡æ”¾ç½®ä½ç½®ï¼ˆç‰©ä½“ä¸­å¿ƒåº”è¯¥åœ¨çš„ä½ç½®ï¼‰
        initial_xy = self._target_pos_init[:, :2]
        target_xy_offset = self._target_xy_offset.unsqueeze(0).repeat(self.num_envs, 1)
        target_xy = initial_xy + target_xy_offset  # ç‰©ä½“ä¸­å¿ƒçš„ç›®æ ‡xyä½ç½®
        
        # 2. æ£€æŸ¥ç‰©ä½“å½“å‰ä½ç½®ï¼ˆxyå¹³é¢ï¼‰
        current_xy = self._target.data.root_pos_w[:, :2]
        pos_error = torch.norm(current_xy - target_xy, dim=1)
        position_check = pos_error < self.cfg.place_position_threshold
        
        # 3. æ£€æŸ¥ç‰©ä½“é«˜åº¦ï¼ˆç¡®ä¿åœ¨æ¡Œé¢ä¸Šï¼Œä¸æ˜¯æ‚¬ç©ºæˆ–æ‰è½ï¼‰
        current_z = self._target.data.root_pos_w[:, 2]
        initial_z = self._target_pos_init[:, 2]
        height_diff = torch.abs(current_z - initial_z)
        height_check = height_diff < 0.01  # é«˜åº¦å·®å°äº1cm
        
        # 4. æ£€æŸ¥æœå‘
        current_quat = self._target.data.root_quat_w
        orientation_loss = self._quat_orientation_loss(self._target_quat_init, current_quat)
        orientation_check = orientation_loss < self.cfg.orientation_threshold
        
        # 5. æ£€æŸ¥æ‰‹æŒ‡æ˜¯å¦å·²æ¾å¼€ï¼ˆæ‰€æœ‰æ¥è§¦åŠ›ä¸º0ï¼‰
        contact_force_num = torch.zeros(self.num_envs, dtype=torch.int8, device=self.device)
        for sensor_name, contact_sensor in self._contact_sensors.items():
            forces = torch.sum(contact_sensor.data.net_forces_w, dim=[1, 2])  # type: ignore
            force_magnitude = torch.abs(forces)  # ä½¿ç”¨åŠ›çš„ç»å¯¹å€¼ï¼ˆå¤§å°ï¼‰
            contact_force_num = torch.where(
                force_magnitude > 0.1,
                contact_force_num + 1,
                contact_force_num
            )
        
        # æ‰‹æŒ‡å·²æ¾å¼€ = æ¥è§¦åŠ›æ•°é‡ä¸º0
        released = contact_force_num < 0.1  # type: ignore
        
        # 6. æ£€æŸ¥æœ«ç«¯æ‰§è¡Œå™¨æ˜¯å¦å·²æŠ¬é«˜åˆ°å®‰å…¨é«˜åº¦
        eef_z = self._robot.data.body_link_pos_w[:, self._eef_link_index, 2]
        required_eef_height = self._target_pos_init[:, 2] + 0.08 # ç‰©ä½“åˆå§‹é«˜åº¦ + 0.15ç±³
        eef_height_check = eef_z >= required_eef_height
        
        # ç»¼åˆåˆ¤æ–­ï¼ˆæ‰€æœ‰æ¡ä»¶éƒ½è¦æ»¡è¶³ï¼‰
        bsuccessed = position_check & height_check & orientation_check & released & eef_height_check
        
        return bsuccessed

    def _get_dones(self) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        # 
        time_out = self.episode_length_buf >= self.max_episode_length - 1
        # task evalutation
        bfailed, self._has_contacted = eval_fail(self._target, self._contact_sensors, self._has_contacted)  # type: ignore
        
        # æ–°å¢ï¼šæ£€æµ‹ç‰©ä½“åœ¨æœªæ¥è§¦æ—¶è¢«ç§»åŠ¨ï¼ˆè¢«æ¨åŠ¨/ç¢°æ’ï¼‰
        bfailed_moved = self._eval_fail_moved_without_contact()
        # bfailed = bfailed | bfailed_moved
        bfailed = bfailed_moved
        
        # success evalï¼ˆä½¿ç”¨ Pick and Place çš„æˆåŠŸåˆ¤æ–­ï¼‰
        bsuccessed = self._eval_success_pick_place()
     
        # update success number
        self._episode_success_num += len(torch.nonzero(bsuccessed == True).squeeze(1).tolist())

        return bsuccessed, bfailed, time_out  # type: ignore
    
    def _reset_idx(self, env_ids: torch.Tensor | None, success_ids:Sequence[int]|None=None):

        # get env indexs
        if env_ids is None or len(env_ids) == self.num_envs:
            env_ids = torch.arange(self.num_envs, dtype=torch.long, device=self.device)

        if success_ids is None:
            success_ids=[]
        
        # æˆªæ–­ logic: ç¡®ä¿ä¿å­˜çš„æ•°æ®ä¸è¶…è¿‡ target_success_count
        ids_to_save = success_ids
        if self.cfg.enable_output and self.cfg.target_success_count and self.cfg.target_success_count > 0:
            # æ³¨æ„: _get_dones å·²ç»æ›´æ–°äº† _episode_success_numï¼ŒåŒ…å«äº†å½“å‰ batch
            current_total = self._episode_success_num
            batch_size = len(success_ids)
            prev_total = current_total - batch_size
            
            if prev_total < self.cfg.target_success_count:
                needed = self.cfg.target_success_count - prev_total
                if batch_size > needed:
                    ids_to_save = success_ids[:needed]
            else:
                ids_to_save = []

        # output data
        if self.cfg.enable_output:
            # è®°å½•ä¿å­˜å‰çš„æ—¶é—´æˆ³ï¼Œç”¨äºæ¨æ–­æ–‡ä»¶è·¯å¾„
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self._data = save_data(
                data=self._data,
                cfg=self.cfg,
                scene=self.scene,
                env_indexs=ids_to_save,
                reset_env_indexs=env_ids.tolist(),
            )
            # æ‰“å°ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
            if ids_to_save:
                saved_path = f"{self.cfg.output_folder}/{timestamp}_data.hdf5"
                print(f"[DATA] å·²ä¿å­˜æ•°æ®: {saved_path} (æˆåŠŸè½¨è¿¹æ•°: {len(ids_to_save)})")


        super()._reset_idx(env_ids)   

        # print logs
        if self.cfg.enable_log:
            self._log_info()
        

        # æ ¹æ®é…ç½®é€‰æ‹©è½¨è¿¹ç”Ÿæˆæ¨¡å¼
        trajectory_mode = getattr(self.cfg, 'trajectory_mode', 'smooth')
        
        # Pick and Place ä½¿ç”¨ä¸“ç”¨è½¨è¿¹ç”Ÿæˆå‡½æ•°
        self.create_pick_place_trajectory(env_ids)



        # reset variables
        self._episode_step[env_ids] = torch.zeros_like(self._episode_step[env_ids])
        self._target_pos_init[env_ids, :] = self._target.data.root_link_pos_w[env_ids, :].clone()
        self._target_quat_init[env_ids, :] = self._target.data.root_quat_w[env_ids, :].clone()  # ä¿å­˜åˆå§‹æœå‘
        self._has_contacted[env_ids] = torch.zeros_like(self._has_contacted[env_ids], device=self.device, dtype=torch.bool)  # type: ignore

    def _log_info(self):
        # log policy evalutation result
        if self.cfg.enable_eval and self._episode_num>0:
            #
            plocy_success_rate = float(self._episode_success_num) / float(self._episode_num)
            info = f"PolicyæˆåŠŸç‡: {plocy_success_rate * 100.0} % "
            info +=f"æˆåŠŸæ¬¡æ•°/æ€»æ¬¡æ•°: {self._episode_success_num}/{self._episode_num}  "
            if self.cfg.enable_output:
                # compute data collect result
                record_time = self._timer.run_time() /60.0
                record_rate = self._episode_success_num / record_time
                info += f"é‡‡é›†æ•ˆç‡: {record_rate:.2f} æ¡/åˆ†é’Ÿ"
            # æ˜¾ç¤ºç›®æ ‡è¿›åº¦ï¼ˆå¦‚æœè®¾ç½®äº†ç›®æ ‡ï¼‰
            if self.cfg.target_success_count and self.cfg.target_success_count > 0:
                info += f" | ç›®æ ‡: {self._episode_success_num}/{self.cfg.target_success_count}"
            print(info, end='\r')
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æˆåŠŸæ¬¡æ•°
        self._check_target_reached()
    
    def _check_target_reached(self):
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡æˆåŠŸæ¬¡æ•°ï¼Œå¦‚æœè¾¾åˆ°åˆ™åœæ­¢ç¨‹åº"""
        if self.cfg.target_success_count and self.cfg.target_success_count > 0:
            if self._episode_success_num >= self.cfg.target_success_count:
                print(f"\n\n{'='*60}")
                print(f"ğŸ‰ å·²è¾¾åˆ°ç›®æ ‡æˆåŠŸæ¬¡æ•°: {self._episode_success_num}/{self.cfg.target_success_count}")
                if self._episode_num > 0:
                    success_rate = float(self._episode_success_num) / float(self._episode_num) * 100
                    print(f"ğŸ“Š æœ€ç»ˆæˆåŠŸç‡: {success_rate:.2f}%")
                if self.cfg.enable_output:
                    record_time = self._timer.run_time() / 60.0
                    print(f"â±ï¸  æ€»è€—æ—¶: {record_time:.2f} åˆ†é’Ÿ")
                    if record_time > 0:
                        print(f"ğŸ“ˆ é‡‡é›†æ•ˆç‡: {self._episode_success_num / record_time:.2f} æ¡/åˆ†é’Ÿ")
                print(f"{'='*60}\n")
                # é€€å‡ºç¨‹åº
                import sys
                sys.exit(0)
